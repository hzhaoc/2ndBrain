### Breakdown/Unbundle a single branch
- compute branch condition
- compute branch target address
- execute branch

Two-step branching:
- separate comparison from branch execution, and store it in some** branch register**
- the delay in between can be filled with other operations
- cons: increase code size

Three-Step branching
- target address (**branch-target register**)
- condition
- control transfer point
- cons: increase code size even more

The branch will be executed in one cluster, not all. There is only one branch being executed in the cluster. But all clusters need to be notified of the branch condition. Clusters only need to be notified of which branch is taken, but they do not affect control of the other clusters. **All branch targets correspond to the same logical block.**

In a DVLIW architecture with unbundled branches, branch targets must be computed separately for each cluster. The branch condition is computed in one cluster and broadcast to all the clusters. If the branch condition is taken, each cluster transfers control to its individual branch target. All of these branch targets correspond to the same logical block. The compiler inserts new branch operations so that all the clusters branch at the same time.

### Multiway branches
A series of control flows where multiple branches are executed close to each other. This can be done by **multiway predication**. think of it being multiple cases.

Multiway branches can be implemented by multiclusters where one cluster focus on addressing and others are responsible for respective condition computation. 
- Multiflow trace: multiple parallel branches in one cycle, each in its own 
- but each cluster should have its own branch unit using local conditions and target.
- Global controller to select the final next Program Counter, but this incurs speed and cost overheads. 
- Benefits: conditional computations are done in parallel
- like before, branching are broken down into several steps in different clusters.

![[multicluster branches.png|600]]

##### Branches and Loops
There is special hardware for zero-overhead looping. There are special instructions: loop-start, loop-end that have zero overhead. There is no bubble overhead. They are popular in DSPs and in IPF’s which also have loop count registers and branch top operations. loop-count registers keep track of the conditions. PowerPC’s have link and counter registers. Link starts where the branch executes.

### Branch Speculation
##### Speculation
- ignore branches and move operations above them
- there are two types of speculation:
	- software: fundamental in VLIW, it is done by the compilers
	- hardware: prevalent in superscalar, but less in VLIW. 

A key aspect of speculation is how to execute possibly dependent codes. 
- Conservative techniques (both hardware and software): Unless legality of reordering can be proven, always serialize operations. 
	- For example: there is a load operation on each side of the branch operation. Since the same load will be executed on both sides of the branch, the load can be reordered above the branch. 
- Speculative techniques (both hardware and software): Executes ahead based on probabilistic assumptions, and fixes the execution if speculation is wrong. 
	- If the speculation is wrong, it must be corrected. Undo the result of the speculation. 
	- **The biggest benefit of speculation: long load latencies can be started early. This will increase ILP. **
	- The downside: there is register pressure, and complexity of exception handling increases. 
- Control Speculation: this is a fundamental technique for ILP machines. 
	- it removes control dependence (moving an instruction above a branch)

##### Speculation exceptions
- how to correctly report exceptions
	- arithmetic operations are always safe. They can just be undone.
	- memory references may throw an exception. 
- There are two choices for handling exceptions generated by mispredicted operations:
	1. Non-recovery speculation model
		- Silent instruction: ignores nonrecoverable exceptions
		- Handling recoverable exceptions is expensive. For example page faults are very expensive to recover from. Embedded systems do not have the hardware complexity to handle complex exceptions. 
		- Not acceptable for precise exceptions. 
		- In embedded systems **the goal of exceptions is to simply signal that an exception has occurred and allow the operating system to take control of the situation. **Therefore a non-recoverable speculation model is sufficient for embedded systems
	2. Recovery Oriented Exception Processing
		- ![[VLIW recovery exception.png|500]]
		- **Branch A**: if the branch is not taken the rest of the code executes. Otherwise,the branch jumps to L1. To hide the latency and delay of the loads, they are moved above the branch. So all these instructions execute speculatively. The check `G` is done and if it fails, then the chain of instructions must be re-executed. So there is a recovery block within instructions `B` and `E`. The other recovery block has `C` and `D` in it. In this case the instructions on which $r4$ is dependent must be re-executed. The recovery blocks do not execute under non-excepting executions. The common case, when the checks do not fail, results in a straight forward run. The speculation has been split into a speculative part and a recovery part. 
		- **This mechanism is complex, but can be implemented in an ALU. It is usually partially implemented in embedded processors.**

### Data Speculation
Is mainly used to make sure the data loaded from memory is the correct value.
- **Run time memory disambiguation**
- For example:
	- move `load`  before `store`  and since it takes longer latency. `store` will be executed before `load` is completed, like a pipeline. 
	- check if two memory locations collide. If so, go to recovery.
		- compiler support version
			- ![[VLIW data speculation.png|500]]
		- hardware support version
			- ![[data speculation VLIW by hardware.png|500]]

### Predication
- predication does not reduce instructions. it removes control dependencies.
- because it removes control dependencies or say, no need to do branch prediction. it is very good with hard-to-predict branches.
- good with short loops
- cons:
	- hardware complexity
	- code bloat
##### full predication
- support conditional tag (predication) for individual operations.
- see also [[ILP - Ctrl Deps. - Branch Predicate]]
- if `$p1` evaluates False, the instruction becomes a NOP.
![[VLIW full predication.png|500]]

##### partial predication
- here only `slct` (conditional select) is used for predication based on the conditional variable `$b1`.  `slct` usage is similar to `cmov` (conditional move)
![[VLIW partial predication.png|500]]

##### predication in embedded domain
partial predication is appealing.

### System operations
System operations → all functions that control system around the CPU. (for example: dealing with I/O and peripherals). 

Most efficient approaches → **control registers**
- memory mapped to **reserved memory page**
- access to these registers is by simple load and store instructions
- still must protect against speculative accesses
- several classes of system operations is possible using control registers
	- synchronization support
	- interrupt support
	- protection and virtual memory support
	- debugging support